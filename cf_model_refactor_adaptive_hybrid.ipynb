{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a092d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import hnswlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4653b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENTS_FILE = \"events.csv\"\n",
    "ITEM_PROP1_FILE = \"item_properties_part1.csv\"\n",
    "ITEM_PROP2_FILE = \"item_properties_part2.csv\"\n",
    "CATEGORY_TREE_FILE = \"category_tree.csv\"\n",
    "CACHE_DIR = \"cache_reco_2\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a918128",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_DIM = 64\n",
    "ITEM_NN_TOPK = 200\n",
    "CF_NEIGHBORS_TOPK = 50\n",
    "HNSW_M = 64\n",
    "HNSW_EF_CONSTRUCTION = 200\n",
    "HNSW_EF_SEARCH = 100\n",
    "MIN_INTERACTIONS_ACTIVE_USER = 1\n",
    "TRAIN_TEST_LAST_N = 3\n",
    "K_EVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b57f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99838999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152ea49",
   "metadata": {},
   "source": [
    "# **Data Loading & Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012bf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    events = pd.read_csv(EVENTS_FILE)\n",
    "    ip1 = pd.read_csv(ITEM_PROP1_FILE)\n",
    "    ip2 = pd.read_csv(ITEM_PROP2_FILE)\n",
    "    cat = pd.read_csv(CATEGORY_TREE_FILE)\n",
    "    item_props = pd.concat([ip1, ip2], axis=0, ignore_index=True)\n",
    "    return events, item_props, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3b1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_events(events: pd.DataFrame) -> pd.DataFrame:\n",
    "    events = events[events['event'].isin(['view', 'addtocart', 'transaction'])].copy()\n",
    "    if not np.issubdtype(events['timestamp'].dtype, np.datetime64):\n",
    "        events['timestamp'] = pd.to_datetime(events['timestamp'], unit='ms', errors='coerce')\n",
    "    weight_map = {'view': 1.0, 'addtocart': 3.0, 'transaction': 5.0}\n",
    "    events['weight'] = events['event'].map(weight_map)\n",
    "    events = events.dropna(subset=['visitorid', 'itemid'])\n",
    "    events['visitorid'] = events['visitorid'].astype(int)\n",
    "    events['itemid'] = events['itemid'].astype(int)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0a7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_last_n(events: pd.DataFrame, n_last=3) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train_rows, test_rows = [], []\n",
    "    for visitor, g in events.groupby('visitorid'):\n",
    "        g = g.sort_values('timestamp')\n",
    "        if len(g) > n_last:\n",
    "            train_rows.append(g.iloc[:-n_last])\n",
    "            test_rows.append(g.iloc[-n_last:])\n",
    "        else:\n",
    "            train_rows.append(g)\n",
    "    train_df = pd.concat(train_rows)\n",
    "    test_df = pd.concat(test_rows)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e677a7e",
   "metadata": {},
   "source": [
    "# **Content-Based Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd7748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_category_matrix(item_props: pd.DataFrame, category_tree: pd.DataFrame) -> pd.DataFrame:\n",
    "    cats = item_props[item_props['property'] == 'categoryid'][['itemid', 'value']].copy()\n",
    "    cats.rename(columns={'value': 'categoryid'}, inplace=True)\n",
    "    cats['categoryid'] = cats['categoryid'].astype(int)\n",
    "    pivot = pd.get_dummies(cats.set_index('itemid')['categoryid'])\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b14c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cb_embeddings(item_features: pd.DataFrame, svd_dim: int = SVD_DIM):\n",
    "    itemids = item_features.index.to_list()\n",
    "    itemid_to_idx = {iid: i for i, iid in enumerate(itemids)}\n",
    "    idx_to_itemid = np.array(itemids)\n",
    "    svd = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "    emb = svd.fit_transform(item_features.values)\n",
    "    emb = normalize(emb)\n",
    "    return emb, itemid_to_idx, idx_to_itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "032bec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hnsw_index(emb: np.ndarray, ef_construction=200, M=64, ef_search=100):\n",
    "    n_items, dim = emb.shape\n",
    "    index = hnswlib.Index(space='cosine', dim=dim)\n",
    "    index.init_index(max_elements=n_items, ef_construction=ef_construction, M=M)\n",
    "    index.add_items(emb, np.arange(n_items))\n",
    "    index.set_ef(ef_search)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457323eb",
   "metadata": {},
   "source": [
    "# **Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0b67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_user_matrix(train_df: pd.DataFrame):\n",
    "    users = train_df['visitorid'].unique()\n",
    "    items = train_df['itemid'].unique()\n",
    "    user_to_idx = {u: i for i, u in enumerate(users)}\n",
    "    item_to_idx = {it: j for j, it in enumerate(items)}\n",
    "    rows, cols, data = [], [], []\n",
    "    for _, row in train_df.iterrows():\n",
    "        rows.append(item_to_idx[row['itemid']])\n",
    "        cols.append(user_to_idx[row['visitorid']])\n",
    "        data.append(row['weight'])\n",
    "    item_user_sparse = csr_matrix((data, (rows, cols)), shape=(len(items), len(users)))\n",
    "    idx_to_itemid = [it for it in items]\n",
    "    return item_user_sparse, idx_to_itemid, item_to_idx, user_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79dc1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_neighbors(item_user_sparse, topk=200, cache_path=None):\n",
    "    if cache_path and os.path.exists(cache_path):\n",
    "        return load_pickle(cache_path)\n",
    "    model = NearestNeighbors(metric='cosine', algorithm='brute', n_jobs=-1)\n",
    "    model.fit(item_user_sparse)\n",
    "    sims, idxs = model.kneighbors(item_user_sparse, n_neighbors=topk)\n",
    "    if cache_path:\n",
    "        save_pickle((idxs, 1 - sims), cache_path)\n",
    "    return idxs, 1 - sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25551b44",
   "metadata": {},
   "source": [
    "# **Adaptive Alpha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680f5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adaptive_alpha(user_id, user_item_matrix, min_alpha=0.1, max_alpha=0.9, slope='linear'):\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return min_alpha\n",
    "    n = (user_item_matrix.loc[user_id] > 0).sum()\n",
    "    if n <= 1:\n",
    "        return min_alpha\n",
    "    max_n = (user_item_matrix > 0).sum(axis=1).max()\n",
    "    frac = n / (max_n + 1e-9)\n",
    "    if slope == 'linear':\n",
    "        alpha = min_alpha + (max_alpha - min_alpha) * frac\n",
    "    elif slope == 'sqrt':\n",
    "        alpha = min_alpha + (max_alpha - min_alpha) * np.sqrt(frac)\n",
    "    else:\n",
    "        alpha = min_alpha + (max_alpha - min_alpha) * frac\n",
    "    return float(np.clip(alpha, min_alpha, max_alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee7341",
   "metadata": {},
   "source": [
    "# **Hybrid Recommender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef9d72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_weighted_recommend_adaptive(\n",
    "    user_id, train_df,\n",
    "    item_user_sparse, idx_to_itemid_itemuser,\n",
    "    item_neighbors_idx, item_neighbors_sims,\n",
    "    itemuser_idx_to_emb_idx, idx_to_itemid_emb_arr, emb_index, emb,\n",
    "    top_n=5, min_alpha=0.1, max_alpha=0.9\n",
    "):\n",
    "    user_item_matrix = train_df.groupby(['visitorid', 'itemid']).size().unstack(fill_value=0)\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return []\n",
    "    alpha = compute_adaptive_alpha(user_id, user_item_matrix, min_alpha, max_alpha)\n",
    "    interacted_items = user_item_matrix.loc[user_id]\n",
    "    interacted_items = interacted_items[interacted_items > 0].index.tolist()\n",
    "\n",
    "    # CF\n",
    "    cf_scores = pd.Series(dtype=float)\n",
    "    for itemid in interacted_items:\n",
    "        if itemid not in idx_to_itemid_itemuser:\n",
    "            continue\n",
    "        item_idx = idx_to_itemid_itemuser.index(itemid)\n",
    "        sim_items = item_neighbors_idx[item_idx]\n",
    "        sim_scores = item_neighbors_sims[item_idx]\n",
    "        for sim_idx, sim_score in zip(sim_items, sim_scores):\n",
    "            sim_itemid = idx_to_itemid_itemuser[sim_idx]\n",
    "            if sim_itemid in interacted_items:\n",
    "                continue\n",
    "            cf_scores[sim_itemid] = cf_scores.get(sim_itemid, 0) + sim_score\n",
    "    cf_scores = cf_scores / (cf_scores.max() + 1e-9)\n",
    "\n",
    "    # CB\n",
    "    cb_scores = pd.Series(dtype=float)\n",
    "    if len(interacted_items) > 0:\n",
    "        last_item = interacted_items[-1]\n",
    "        if last_item in itemuser_idx_to_emb_idx:\n",
    "            emb_idx = itemuser_idx_to_emb_idx[last_item]\n",
    "            labels, distances = emb_index.knn_query(emb[emb_idx], k=200)\n",
    "            cb_items = [idx_to_itemid_emb_arr[i] for i in labels[0][1:]]\n",
    "            cb_scores = pd.Series(1 - distances[0][1:], index=cb_items)\n",
    "    cb_scores = cb_scores / (cb_scores.max() + 1e-9)\n",
    "\n",
    "    all_items = cf_scores.index.union(cb_scores.index)\n",
    "    cf_vals = cf_scores.reindex(all_items).fillna(0)\n",
    "    cb_vals = cb_scores.reindex(all_items).fillna(0)\n",
    "    hybrid = alpha * cf_vals + (1 - alpha) * cb_vals\n",
    "    hybrid = hybrid[~hybrid.index.isin(interacted_items)]\n",
    "    recs = hybrid.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b712cb4",
   "metadata": {},
   "source": [
    "# **Evaluation Adaptive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d22732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_item_cf_adaptive(\n",
    "    train_df, test_df, item_features,\n",
    "    emb, itemuser_idx_to_emb_idx, idx_to_itemid_emb_arr, emb_index,\n",
    "    item_user_sparse, idx_to_itemid_itemuser,\n",
    "    item_neighbors_idx, item_neighbors_sims,\n",
    "    min_alpha=0.1, max_alpha=0.9, k=5\n",
    "):\n",
    "    true_items_per_user = test_df.groupby(\"visitorid\")[\"itemid\"].apply(list).to_dict()\n",
    "    metrics = []\n",
    "    for user_id, true_items in tqdm(true_items_per_user.items(), desc=\"Adaptive Eval\"):\n",
    "        recs = hybrid_weighted_recommend_adaptive(\n",
    "            user_id, train_df,\n",
    "            item_user_sparse, idx_to_itemid_itemuser,\n",
    "            item_neighbors_idx, item_neighbors_sims,\n",
    "            itemuser_idx_to_emb_idx, idx_to_itemid_emb_arr, emb_index, emb,\n",
    "            top_n=k, min_alpha=min_alpha, max_alpha=max_alpha\n",
    "        )\n",
    "        hits = len(set(recs) & set(true_items))\n",
    "        precision = hits / k\n",
    "        recall = hits / len(true_items)\n",
    "        hitrate = 1 if hits > 0 else 0\n",
    "        metrics.append((precision, recall, hitrate))\n",
    "    df = pd.DataFrame(metrics, columns=[\"Precision\", \"Recall\", \"HitRate\"])\n",
    "    return df.mean().to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917824e",
   "metadata": {},
   "source": [
    "# **Main Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6637e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    events, item_props, category_tree = load_data()\n",
    "    events = preprocess_events(events)\n",
    "\n",
    "    print(\"Train/Test Split...\")\n",
    "    train_df, test_df = train_test_split_by_last_n(events, TRAIN_TEST_LAST_N)\n",
    "\n",
    "    print(\"Building features...\")\n",
    "    item_features = build_item_category_matrix(item_props, category_tree)\n",
    "    emb, itemid_to_emb_idx_map, idx_to_itemid_emb_arr = build_cb_embeddings(item_features)\n",
    "    emb_index = build_hnsw_index(emb)\n",
    "\n",
    "    print(\"Building CF...\")\n",
    "    item_user_sparse, idx_to_itemid_itemuser, _, _ = build_item_user_matrix(train_df)\n",
    "    item_neighbors_idx, item_neighbors_sims = build_item_neighbors(item_user_sparse, ITEM_NN_TOPK)\n",
    "\n",
    "    print(\"Evaluating adaptive hybrid recommender...\")\n",
    "    results = evaluate_hybrid_item_cf_adaptive(\n",
    "        train_df, test_df, item_features,\n",
    "        emb, itemid_to_emb_idx_map, idx_to_itemid_emb_arr, emb_index,\n",
    "        item_user_sparse, idx_to_itemid_itemuser,\n",
    "        item_neighbors_idx, item_neighbors_sims,\n",
    "        min_alpha=0.1, max_alpha=0.9, k=K_EVAL\n",
    "    )\n",
    "    print(\"\\n===== Final Adaptive Evaluation Results =====\")\n",
    "    print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train/Test Split...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
